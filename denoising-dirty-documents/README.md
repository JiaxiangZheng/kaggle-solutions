这里尝试给出两种方案解决这个问题。

### 方法一

简单地使用中值滤波器对原始图像进行过滤，将滤波后的结果与原始图像作 diff，得到产生的背景图。这些，原始图减掉背景图就是 denoise 后的结果了。参考 `signal-denoising.py` 中的实现。对测试集运行的 MSR 误差大概在 0.06 左右。生成结果提交 Kaggle 的结果也大致在 0.06。

### 方法二

可以考虑对原始图像进行分割出一系列小的 patch 图像，直接构建神经网络对 patch 图像进行训练，这样一方面训练的样本量可以扩大，另一方面可以直接学习出一个比较可靠的卷积核对图像进行过滤，生成合理的结果。

方法参考 `train.py`, `clean.py`, `sumbit.py`。